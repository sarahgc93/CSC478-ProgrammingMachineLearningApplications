{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSC 478 Assignment 3\n",
    "### Sarah Cummings\n",
    "\n",
    "### Question 1: Linear Regression with Communities Dataset\n",
    "##### A) Load and preprocess the data using Pandas or Numpy, or sklearn. Seperate the target attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import operator\n",
    "#from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state        communityname  population  householdsize  racepctblack  \\\n",
       "0      8         Lakewoodcity        0.19           0.33          0.02   \n",
       "1     53          Tukwilacity        0.00           0.16          0.12   \n",
       "2     24         Aberdeentown        0.00           0.42          0.49   \n",
       "3     34  Willingborotownship        0.04           0.77          1.00   \n",
       "4     42    Bethlehemtownship        0.01           0.55          0.02   \n",
       "\n",
       "   racePctWhite  racePctAsian  racePctHisp  agePct12t21  agePct12t29  \\\n",
       "0          0.90          0.12         0.17         0.34         0.47   \n",
       "1          0.74          0.45         0.07         0.26         0.59   \n",
       "2          0.56          0.17         0.04         0.39         0.47   \n",
       "3          0.08          0.12         0.10         0.51         0.50   \n",
       "4          0.95          0.09         0.05         0.38         0.38   \n",
       "\n",
       "          ...           NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "0         ...                 0.0            0.12              0.42   \n",
       "1         ...                 0.0            0.21              0.50   \n",
       "2         ...                 0.0            0.14              0.49   \n",
       "3         ...                 0.0            0.19              0.30   \n",
       "4         ...                 0.0            0.11              0.72   \n",
       "\n",
       "   PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "0            0.50           0.51            0.64      0.12     0.26   \n",
       "1            0.34           0.60            0.52      0.02     0.12   \n",
       "2            0.54           0.67            0.56      0.01     0.21   \n",
       "3            0.73           0.64            0.65      0.02     0.39   \n",
       "4            0.64           0.61            0.53      0.04     0.09   \n",
       "\n",
       "   PctUsePubTrans  ViolentCrimesPerPop  \n",
       "0            0.20                 0.20  \n",
       "1            0.45                 0.67  \n",
       "2            0.02                 0.43  \n",
       "3            0.28                 0.12  \n",
       "4            0.02                 0.03  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "c_df = pd.read_csv(r\"/Users/sarahcummings/Documents/csc478/assignment3/communities/communities.csv\",encoding = \"ISO-8859-1\", low_memory=False)\n",
    "#c_df = pd.read_csv(r\"C:\\Users\\scummings\\Desktop\\MyFiles\\school\\csc478_3\\communities/communities.csv\",encoding = \"ISO-8859-1\", low_memory=False)\n",
    "\n",
    "c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Jacksonvillecity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.683551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057593</td>\n",
       "      <td>0.463395</td>\n",
       "      <td>0.179629</td>\n",
       "      <td>0.753716</td>\n",
       "      <td>0.153681</td>\n",
       "      <td>0.144022</td>\n",
       "      <td>0.424218</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.215552</td>\n",
       "      <td>0.608892</td>\n",
       "      <td>0.535050</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.651530</td>\n",
       "      <td>0.065231</td>\n",
       "      <td>0.232854</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>0.237979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.397553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>0.163717</td>\n",
       "      <td>0.253442</td>\n",
       "      <td>0.244039</td>\n",
       "      <td>0.208877</td>\n",
       "      <td>0.232492</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.231134</td>\n",
       "      <td>0.204329</td>\n",
       "      <td>0.181352</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.198221</td>\n",
       "      <td>0.109459</td>\n",
       "      <td>0.203092</td>\n",
       "      <td>0.229055</td>\n",
       "      <td>0.232985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              state     communityname   population  householdsize  \\\n",
       "count   1994.000000              1994  1994.000000    1994.000000   \n",
       "unique          NaN              1828          NaN            NaN   \n",
       "top             NaN  Jacksonvillecity          NaN            NaN   \n",
       "freq            NaN                 5          NaN            NaN   \n",
       "mean      28.683551               NaN     0.057593       0.463395   \n",
       "std       16.397553               NaN     0.126906       0.163717   \n",
       "min        1.000000               NaN     0.000000       0.000000   \n",
       "25%       12.000000               NaN     0.010000       0.350000   \n",
       "50%       34.000000               NaN     0.020000       0.440000   \n",
       "75%       42.000000               NaN     0.050000       0.540000   \n",
       "max       56.000000               NaN     1.000000       1.000000   \n",
       "\n",
       "        racepctblack  racePctWhite  racePctAsian  racePctHisp  agePct12t21  \\\n",
       "count    1994.000000   1994.000000   1994.000000  1994.000000  1994.000000   \n",
       "unique           NaN           NaN           NaN          NaN          NaN   \n",
       "top              NaN           NaN           NaN          NaN          NaN   \n",
       "freq             NaN           NaN           NaN          NaN          NaN   \n",
       "mean        0.179629      0.753716      0.153681     0.144022     0.424218   \n",
       "std         0.253442      0.244039      0.208877     0.232492     0.155196   \n",
       "min         0.000000      0.000000      0.000000     0.000000     0.000000   \n",
       "25%         0.020000      0.630000      0.040000     0.010000     0.340000   \n",
       "50%         0.060000      0.850000      0.070000     0.040000     0.400000   \n",
       "75%         0.230000      0.940000      0.170000     0.160000     0.470000   \n",
       "max         1.000000      1.000000      1.000000     1.000000     1.000000   \n",
       "\n",
       "        agePct12t29         ...             NumStreet  PctForeignBorn  \\\n",
       "count   1994.000000         ...           1994.000000     1994.000000   \n",
       "unique          NaN         ...                   NaN             NaN   \n",
       "top             NaN         ...                   NaN             NaN   \n",
       "freq            NaN         ...                   NaN             NaN   \n",
       "mean       0.493867         ...              0.022778        0.215552   \n",
       "std        0.143564         ...              0.100400        0.231134   \n",
       "min        0.000000         ...              0.000000        0.000000   \n",
       "25%        0.410000         ...              0.000000        0.060000   \n",
       "50%        0.480000         ...              0.000000        0.130000   \n",
       "75%        0.540000         ...              0.000000        0.280000   \n",
       "max        1.000000         ...              1.000000        1.000000   \n",
       "\n",
       "        PctBornSameState  PctSameHouse85  PctSameCity85  PctSameState85  \\\n",
       "count        1994.000000     1994.000000    1994.000000     1994.000000   \n",
       "unique               NaN             NaN            NaN             NaN   \n",
       "top                  NaN             NaN            NaN             NaN   \n",
       "freq                 NaN             NaN            NaN             NaN   \n",
       "mean            0.608892        0.535050       0.626424        0.651530   \n",
       "std             0.204329        0.181352       0.200521        0.198221   \n",
       "min             0.000000        0.000000       0.000000        0.000000   \n",
       "25%             0.470000        0.420000       0.520000        0.560000   \n",
       "50%             0.630000        0.540000       0.670000        0.700000   \n",
       "75%             0.777500        0.660000       0.770000        0.790000   \n",
       "max             1.000000        1.000000       1.000000        1.000000   \n",
       "\n",
       "           LandArea      PopDens  PctUsePubTrans  ViolentCrimesPerPop  \n",
       "count   1994.000000  1994.000000     1994.000000          1994.000000  \n",
       "unique          NaN          NaN             NaN                  NaN  \n",
       "top             NaN          NaN             NaN                  NaN  \n",
       "freq            NaN          NaN             NaN                  NaN  \n",
       "mean       0.065231     0.232854        0.161685             0.237979  \n",
       "std        0.109459     0.203092        0.229055             0.232985  \n",
       "min        0.000000     0.000000        0.000000             0.000000  \n",
       "25%        0.020000     0.100000        0.020000             0.070000  \n",
       "50%        0.040000     0.170000        0.070000             0.150000  \n",
       "75%        0.070000     0.280000        0.190000             0.330000  \n",
       "max        1.000000     1.000000        1.000000             1.000000  \n",
       "\n",
       "[11 rows x 100 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute and display basic statistics (mean, standard deviation, min, max\n",
    "c_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                      int64\n",
       "communityname             object\n",
       "population               float64\n",
       "householdsize            float64\n",
       "racepctblack             float64\n",
       "racePctWhite             float64\n",
       "racePctAsian             float64\n",
       "racePctHisp              float64\n",
       "agePct12t21              float64\n",
       "agePct12t29              float64\n",
       "agePct16t24              float64\n",
       "agePct65up               float64\n",
       "numbUrban                float64\n",
       "pctUrban                 float64\n",
       "medIncome                float64\n",
       "pctWWage                 float64\n",
       "pctWFarmSelf             float64\n",
       "pctWInvInc               float64\n",
       "pctWSocSec               float64\n",
       "pctWPubAsst              float64\n",
       "pctWRetire               float64\n",
       "medFamInc                float64\n",
       "perCapInc                float64\n",
       "whitePerCap              float64\n",
       "blackPerCap              float64\n",
       "indianPerCap             float64\n",
       "AsianPerCap              float64\n",
       "OtherPerCap               object\n",
       "HispPerCap               float64\n",
       "NumUnderPov              float64\n",
       "                          ...   \n",
       "MedNumBR                 float64\n",
       "HousVacant               float64\n",
       "PctHousOccup             float64\n",
       "PctHousOwnOcc            float64\n",
       "PctVacantBoarded         float64\n",
       "PctVacMore6Mos           float64\n",
       "MedYrHousBuilt           float64\n",
       "PctHousNoPhone           float64\n",
       "PctWOFullPlumb           float64\n",
       "OwnOccLowQuart           float64\n",
       "OwnOccMedVal             float64\n",
       "OwnOccHiQuart            float64\n",
       "RentLowQ                 float64\n",
       "RentMedian               float64\n",
       "RentHighQ                float64\n",
       "MedRent                  float64\n",
       "MedRentPctHousInc        float64\n",
       "MedOwnCostPctInc         float64\n",
       "MedOwnCostPctIncNoMtg    float64\n",
       "NumInShelters            float64\n",
       "NumStreet                float64\n",
       "PctForeignBorn           float64\n",
       "PctBornSameState         float64\n",
       "PctSameHouse85           float64\n",
       "PctSameCity85            float64\n",
       "PctSameState85           float64\n",
       "LandArea                 float64\n",
       "PopDens                  float64\n",
       "PctUsePubTrans           float64\n",
       "ViolentCrimesPerPop      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine varaible types\n",
    "c_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Correct for the ? in data\n",
    "c_df.OtherPerCap=pd.to_numeric(c_df.OtherPerCap, errors='coerce') \n",
    "c_df = c_df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate the target attribute for regression.\n",
    "y = np.array(c_df.ViolentCrimesPerPop)\n",
    "#Pull the categorical vars from the X that we will need for regression\n",
    "X = np.array(c_df.drop(['ViolentCrimesPerPop', 'state', 'communityname'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1993,) (1993, 97)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape,X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Perform standard linear regression on data  using the implementation for Ch. 8 of MLA. Compute the RMSE value on the full training data, plot the correlation between the predicted and actual values of the target attribute, display the obtained regression coefficients (weights). Finally, perform 10-fold cross-validation and compare the cross-validation RMSE to the training RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function from the Machine Learning in Action Book-- pg 157\n",
    "\n",
    "#prep the X var set such that we can have a constant\n",
    "#x_var = np.array(X)\n",
    "#x_var = np.array([np.concatenate((v,[1])) for v in x_var])\n",
    "\n",
    "def standRegres(xArr, yArr):\n",
    "    xMat = np.matrix(xArr) ; yMat = np.matrix(yArr).T\n",
    "    xTx = xMat.T*xMat\n",
    "    if np.linalg.det(xTx) == 0.0:\n",
    "        print(\"This matrix is singular, cannot do inverse\")\n",
    "    else:\n",
    "        ws = xTx.I * (xMat.T*yMat)\n",
    "        return ws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.14753045],\n",
       "        [-0.02816632],\n",
       "        [ 0.24261797],\n",
       "        [-0.00159634],\n",
       "        [ 0.01150284],\n",
       "        [ 0.10644182],\n",
       "        [ 0.18985213],\n",
       "        [-0.09097503],\n",
       "        [-0.25975459],\n",
       "        [ 0.16636631],\n",
       "        [-0.253063  ],\n",
       "        [ 0.04772706],\n",
       "        [-0.1823868 ],\n",
       "        [-0.13361716],\n",
       "        [ 0.04824077],\n",
       "        [-0.13030763],\n",
       "        [ 0.09512969],\n",
       "        [ 0.0321094 ],\n",
       "        [-0.07190648],\n",
       "        [ 0.2463212 ],\n",
       "        [ 0.09228257],\n",
       "        [-0.29747294],\n",
       "        [-0.02599742],\n",
       "        [-0.03438455],\n",
       "        [ 0.0249581 ],\n",
       "        [ 0.04217876],\n",
       "        [ 0.03745346],\n",
       "        [ 0.0820154 ],\n",
       "        [-0.14197371],\n",
       "        [-0.09911038],\n",
       "        [ 0.07412209],\n",
       "        [ 0.1260963 ],\n",
       "        [ 0.01704273],\n",
       "        [ 0.27039384],\n",
       "        [-0.03912943],\n",
       "        [-0.00861928],\n",
       "        [ 0.5475927 ],\n",
       "        [ 0.24559331],\n",
       "        [ 0.26377363],\n",
       "        [-0.65353994],\n",
       "        [-0.15499415],\n",
       "        [ 0.06700405],\n",
       "        [-0.26707716],\n",
       "        [-0.0297381 ],\n",
       "        [ 0.0019009 ],\n",
       "        [ 0.06105849],\n",
       "        [-0.18746594],\n",
       "        [-0.13557222],\n",
       "        [ 0.15722358],\n",
       "        [-0.13782654],\n",
       "        [ 0.02693829],\n",
       "        [ 0.03426659],\n",
       "        [-0.08588121],\n",
       "        [ 0.04010041],\n",
       "        [-0.03299096],\n",
       "        [-0.24278694],\n",
       "        [ 0.49771545],\n",
       "        [-0.23391561],\n",
       "        [ 0.04450365],\n",
       "        [-0.12349645],\n",
       "        [ 0.0710047 ],\n",
       "        [-0.27635045],\n",
       "        [ 0.65570102],\n",
       "        [ 0.00250275],\n",
       "        [-0.21007103],\n",
       "        [-0.69089622],\n",
       "        [ 0.18636784],\n",
       "        [ 0.15233714],\n",
       "        [ 0.03581777],\n",
       "        [ 0.18489986],\n",
       "        [-0.03688693],\n",
       "        [ 0.60519851],\n",
       "        [ 0.04206855],\n",
       "        [-0.06713613],\n",
       "        [-0.01889742],\n",
       "        [ 0.01298893],\n",
       "        [-0.01542782],\n",
       "        [-0.38976856],\n",
       "        [ 0.30191188],\n",
       "        [ 0.00826827],\n",
       "        [-0.25449719],\n",
       "        [-0.02678002],\n",
       "        [-0.07102765],\n",
       "        [ 0.38190307],\n",
       "        [ 0.04726423],\n",
       "        [-0.03487438],\n",
       "        [-0.08223632],\n",
       "        [ 0.14246213],\n",
       "        [ 0.1754713 ],\n",
       "        [ 0.1533781 ],\n",
       "        [ 0.02335978],\n",
       "        [-0.01436014],\n",
       "        [ 0.03480558],\n",
       "        [ 0.0033619 ],\n",
       "        [ 0.02112081],\n",
       "        [-0.00244081],\n",
       "        [-0.03893743]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform the standard linear reg\n",
    "s_lin = standRegres(X, y)\n",
    "# Display the obtained regression coefficients (weights).\n",
    "s_lin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12896427]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the RMSE value on the full training data\n",
    "yHat = X*s_lin\n",
    "yHatT = yHat.T\n",
    "err = abs(yHatT - y)\n",
    "total_error = np.dot(err,err.T)\n",
    "rmse = np.sqrt(total_error/len(yHat))\n",
    "print(rmse) \n",
    "#print(yHatT,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSkIQBEHQ8v8B9zgi95+J3rUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1072e45c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the correlation between the predicted and actual values of the target attribute.\n",
    "\n",
    "#create a scatter as in the population example\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(yHatT,y)\n",
    "\n",
    "\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Perform 10-fold cross-validation and compare the cross-validation RMSE to the training RMSE\n",
    "from sklearn import cross_validation\n",
    "#dat=c_df.drop(['state', 'communityname'], axis=1)\n",
    "##dat.head()\n",
    "\n",
    "#cv_scores = cross_validation.cross_val_score(standRegerss, dat, y, cv=10)\n",
    "#sr=standRegress.fit(x_var,y)\n",
    "\n",
    "#I have no idea why this isn't working with my standard lin fuction so im going to use the regular function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rmse: 0.128691194406      10 fold rmse: 0.136298055672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, SGDRegressor\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import cross_validation\n",
    "## 10 fold cross vaidation\n",
    "lin=LinearRegression()\n",
    "fit_LR=lin.fit(X, y)\n",
    "\n",
    "#create the fit\n",
    "linrdf=lin.predict(X)\n",
    "error=linrdf-y\n",
    "totalErr=np.dot(error,error)\n",
    "rmse_train=np.sqrt(totalErr/len(linrdf))\n",
    "\n",
    "\n",
    "#divide data into folds\n",
    "kf = KFold(len(X), n_folds=10)\n",
    "xval_err = 0\n",
    "\n",
    "#calculate the rmse for the 10 folds\n",
    "for train,test in kf:\n",
    "    lin.fit(X[train],y[train])\n",
    "    # p = np.array([linreg.predict(xi) for xi in x[test]])\n",
    "    p = lin.predict(X[test])\n",
    "    e = p-y[test]\n",
    "    xval_err += np.dot(e,e)\n",
    "    \n",
    "rmse_10cv = np.sqrt(xval_err/len(X))\n",
    "\n",
    "print(\"Original rmse:\",rmse_train,\"     10 fold rmse:\",rmse_10cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From the rmse values, we see our original rmse is lower than the 10 fold validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Feature Selection:  use the scikit-learn regression model from sklearn.linear_model with a subset of features to perform linear regression. For feature selection, write a script or function that takes as input the training data, target attribute; the model; and any other parameters you find necessary, and returns the optimal percentage of the most informative features to use. Your approach should use k-fold cross-validation on the training data (you can use k=5). You can use feature_selection.SelectPercentile to find the most informative variables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1594,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import feature_selection\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg=linreg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectPercentile(percentile=10,\n",
       "         score_func=<function f_regression at 0x111816950>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fSelector = SelectPercentile(f_regression, percentile=10)\n",
    "fSelector.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31  0.69  0.39 ...,  0.71  0.59  0.2 ]\n",
      " [ 0.41  0.65  0.35 ...,  0.64  0.55  0.24]\n",
      " [ 0.02  0.97  0.68 ...,  0.81  0.76  0.05]\n",
      " ..., \n",
      " [ 0.19  0.81  0.47 ...,  0.57  0.54  0.27]\n",
      " [ 0.52  0.51  0.33 ...,  0.69  0.47  0.25]\n",
      " [ 0.01  0.99  0.75 ...,  0.81  0.87  0.1 ]]\n"
     ]
    }
   ],
   "source": [
    "X_train_fs = fSelector.fit_transform(X_train, y_train)\n",
    "print(X_train_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.536089414844\n",
      "6 0.592040520825\n",
      "11 0.601778965892\n",
      "16 0.606537859606\n",
      "21 0.61956860089\n",
      "26 0.627805572525\n",
      "31 0.632700961662\n",
      "36 0.635784521561\n",
      "41 0.638294905898\n",
      "46 0.633828811687\n",
      "51 0.634102772635\n",
      "56 0.633566155789\n",
      "61 0.632453759348\n",
      "66 0.630731851445\n",
      "71 0.629205102154\n",
      "76 0.63112482526\n",
      "81 0.631764224671\n",
      "86 0.634611061522\n",
      "91 0.632987681144\n",
      "96 0.639997020136\n",
      "Optimal percentile of features:96 \n",
      "\n",
      "Optimal number of features:93 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:18: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:19: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "import math\n",
    "# Write a script or function that takes as input the training data, target attribute; the model; and any other parameters you find necessary, and returns the optimal percentage of the most informative features to use. \n",
    "\n",
    "percentiles = range(1, 100, 5)\n",
    "results = []\n",
    "for i in range(1, 100, 5):\n",
    "    fSelector = SelectPercentile(f_regression, percentile=i)\n",
    "    fSelector.fit(X, y)\n",
    "    X_train_fs = fSelector.fit_transform(X_train, y_train)\n",
    "    #fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=i)\n",
    "    #X_train_fs = fs.fit_transform(X_train, y_train)\n",
    "    scores = cross_validation.cross_val_score(linreg, X_train_fs, y_train, cv=5)\n",
    "    print(i,scores.mean())\n",
    "    results = np.append(results, scores.mean())\n",
    "\n",
    "optimal_percentil = np.where(results == results.max())[0]\n",
    "print(\"Optimal percentile of features:{0}\".format(percentiles[optimal_percentil]), \"\\n\")\n",
    "optimal_num_features = int(math.floor(percentiles[optimal_percentil]*X.shape[1]/100))\n",
    "print(\"Optimal number of features:{0}\".format(optimal_num_features), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1057b07f0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111d77160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot percentile of features VS. cross-validation scores\n",
    "import pylab as pl\n",
    "pl.figure()\n",
    "pl.xlabel(\"Percentage of features selected\")\n",
    "pl.ylabel(\"Cross validation accuracy\")\n",
    "pl.plot(percentiles,results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Perform Ridge Regression and Lasso Regression, however this time use the modules from  sklearn.linear_model. In each case, perform systematic model selection to identify the optimal alpha parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, create a 20%-80% randomized split of the data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a function that takes as input the data and target attribute; the parameter to vary and a list of its values; the model to be trained; and any other relevant input needed to determine the optimal value for the specified parameter.\n",
    "\n",
    "def regressionComparisons(X,y,alpha):\n",
    "    for method in[LinearRegression(),ElasticNet(fit_intercept=True, alpha=alpha),\n",
    "                 Lasso(fit_intercept=True, alpha=alpha),Ridge(fit_intercept=True, alpha=alpha)]:\n",
    "        #compute rmse on training\n",
    "        method.fit(X,y)\n",
    "        yHats=method.predict(X)\n",
    "        error=yHats-y\n",
    "        total_error=np.dot(error,error)\n",
    "        rmse_train=np.sqrt(total_error/len(yHats))\n",
    "        \n",
    "        #compute rmse on kfold \n",
    "        kf=KFold(len(X), n_folds=5)\n",
    "        err=0\n",
    "        \n",
    "        for train, test in kf:\n",
    "            method.fit(X[train],y[train])\n",
    "            yHats=method.predict(X[test])\n",
    "            error=yHats-y[test]\n",
    "            err+=np.dot(error,error)\n",
    "            rmse_5cv = np.sqrt(err/len(X))\n",
    "        print('Method: ', method)\n",
    "        print('RMSE on training: ', rmse_train)\n",
    "        print('RMSE on 5-fold CV: ', rmse_5cv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE on training:  0.12752697698\n",
      "RMSE on 5-fold CV:  0.137106388298\n",
      "Method:  ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE on training:  0.229696952752\n",
      "RMSE on 5-fold CV:  0.230081413263\n",
      "Method:  Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE on training:  0.229696952752\n",
      "RMSE on 5-fold CV:  0.230081413263\n",
      "Method:  Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "RMSE on training:  0.127708733168\n",
      "RMSE on 5-fold CV:  0.136263525903\n"
     ]
    }
   ],
   "source": [
    "x_var = np.array(X_train)\n",
    "#x_var = np.array([np.concatenate((v,[1])) for v in x_var])\n",
    "regressionComparisons(X_train,y_train,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE on training:  0.12752697698\n",
      "RMSE on 5-fold CV:  0.137106388298\n",
      "Method:  ElasticNet(alpha=0.2, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE on training:  0.229696952752\n",
      "RMSE on 5-fold CV:  0.230081413263\n",
      "Method:  Lasso(alpha=0.2, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE on training:  0.229696952752\n",
      "RMSE on 5-fold CV:  0.230081413263\n",
      "Method:  Ridge(alpha=0.2, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "RMSE on training:  0.127878746569\n",
      "RMSE on 5-fold CV:  0.136029988239\n"
     ]
    }
   ],
   "source": [
    "regressionComparisons(x_var,y_train,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE on training:  0.12752697698\n",
      "RMSE on 5-fold CV:  0.137106388298\n",
      "Method:  ElasticNet(alpha=0.3, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE on training:  0.229696952752\n",
      "RMSE on 5-fold CV:  0.230081413263\n",
      "Method:  Lasso(alpha=0.3, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE on training:  0.229696952752\n",
      "RMSE on 5-fold CV:  0.230081413263\n",
      "Method:  Ridge(alpha=0.3, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "RMSE on training:  0.128026173104\n",
      "RMSE on 5-fold CV:  0.135905198575\n"
     ]
    }
   ],
   "source": [
    "regressionComparisons(x_var,y_train,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1057c37b8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAExCAYAAAB71MlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111ec90b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the error values on the training and cross-validation splits across the specified values of the alpha parameter. \n",
    "\n",
    "\n",
    "#put the values from above into a pandas df\n",
    "d = {'method' : pd.Series([\"linear\", \"ElasticNet\", \"Lasso\",\"Ridge\"], index=[\"linear\", \"ElasticNet\", \"Lasso\",\"Ridge\"]),\n",
    "     'rsmeTrain' : pd.Series([0.128691194406, 0.232984833141, 0.232984833141, 0.128937729639], index=[\"linear\", \"ElasticNet\", \"Lasso\",\"Ridge\"]),\n",
    "    'rsmeCV' : pd.Series([0.13752029088,  0.233130227241, 0.233130227241,  0.136481581966], index=[\"linear\", \"ElasticNet\", \"Lasso\",\"Ridge\"])}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df.plot(kind='bar',title=\"Errors with a=0.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE on training:  0.114241919826\n",
      "RMSE on 5-fold CV:  0.169967875244\n",
      "Method:  ElasticNet(alpha=0.3, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE on training:  0.245679000155\n",
      "RMSE on 5-fold CV:  0.246208929896\n",
      "Method:  Lasso(alpha=0.3, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE on training:  0.245679000155\n",
      "RMSE on 5-fold CV:  0.246208929896\n",
      "Method:  Ridge(alpha=0.3, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "RMSE on training:  0.119628810744\n",
      "RMSE on 5-fold CV:  0.150931364762\n"
     ]
    }
   ],
   "source": [
    "#Finally, using the best alpha value, run the model on the set-aside test data.\n",
    "\n",
    "regressionComparisons(X_test,y_test,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Discuss Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From our earlier results, we found that with our training data, teh ridge regression with a=0.3 produced the best rmse. On the test data, the rmse with  ridge regression is 0.11962, which is even better than it was with out training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E) Next, perform regression using Stochastic Gradient Descent for regression. For this part, you should use the  SGDRegessor module from sklearn.linear_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Standardise as prep for this model\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x_var)\n",
    "x_s=scaler.transform(x_var)\n",
    "\n",
    "\n",
    "sgdModel=SGDRegressor(penalty='l2', alpha=0.15, n_iter=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent Regression\n",
      "RMSE on training:  0.145627646169\n",
      "RMSE on 10-fold CV:  0.23908189805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#As in d, calculate the RMSE with the training and testing data\n",
    "\n",
    "sgdModel.fit(x_var,y_train)\n",
    "yHats=sgdModel.predict(x_var)\n",
    "error=yHats-y_train\n",
    "total_error=np.dot(error,error)\n",
    "rmse_train=np.sqrt(total_error/len(yHats))\n",
    "\n",
    "# RMSE using 10-fold cross-validation\n",
    "\n",
    "kf=KFold(len(x_var), n_folds=10)\n",
    "xval_err = 0\n",
    "for train, test in kf:\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(x_var[train])\n",
    "    xtrain_s = scaler.transform(x_var[train])\n",
    "    xtest_s = scaler.transform(x_var[test])\n",
    "    sgdModel.fit(xtrain_s, y[train])\n",
    "    yHats=sgdModel.predict(xtest_s)\n",
    "    error=yHats-y[test]\n",
    "    xval_err += np.dot(error,error)\n",
    "rmse_10cv=np.sqrt(xval_err/len(x_var))\n",
    "\n",
    "print(\"Stochastic Gradient Descent Regression\")\n",
    "print('RMSE on training: ', rmse_train)\n",
    "print('RMSE on 10-fold CV: ', rmse_10cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen parameter on 100 datapoints: {'alpha': 0.001, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "#Use Grid Search to find the best params\n",
    "\n",
    "est = GridSearchCV(SGDRegressor(),\n",
    "                   param_grid={\"penalty\":['l2', 'l1'],\n",
    "                               \"alpha\":[0.15,0.05,0.01,0.001,0.0001]})\n",
    "                                     \n",
    "print(\"Chosen parameter on 100 datapoints: %s\" % est.fit(X, y).best_params_  )                                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', n_iter=200, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the best parameters, apply the model to the set-aside test data.\n",
    "\n",
    "sgdBest=SGDRegressor(penalty='l2',alpha=0.0001,n_iter=200)\n",
    "sgdBest.fit(X[test],y[test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.536018962249\n",
      "6 0.587507025319\n",
      "11 0.599730240175\n",
      "16 0.605215101544\n",
      "21 0.615281613675\n",
      "26 0.62492303881\n",
      "31 0.630045868736\n",
      "36 0.63130640991\n",
      "41 0.632762226132\n",
      "46 0.632035608926\n",
      "51 0.631948465603\n",
      "56 0.633237610914\n",
      "61 0.631402415532\n",
      "66 0.63040115797\n",
      "71 0.631356761757\n",
      "76 0.633607859389\n",
      "81 0.633755543907\n",
      "86 0.637581158642\n",
      "91 0.634949467806\n",
      "96 0.640692590644\n",
      "Optimal percentile of features:96 \n",
      "\n",
      "Optimal number of features:93 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:16: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:17: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "#Finally, perform model selection (similar to part d, above) to find the best \"l1_ratio\" \n",
    "\n",
    "percentiles = range(1, 100, 5)\n",
    "results = []\n",
    "for i in range(1, 100, 5):\n",
    "    fSelector = SelectPercentile(f_regression, percentile=i)\n",
    "    fSelector.fit(X, y)\n",
    "    X_train_fs = fSelector.fit_transform(X_train, y_train)\n",
    "    #fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=i)\n",
    "    #X_train_fs = fs.fit_transform(X_train, y_train)\n",
    "    scores = cross_validation.cross_val_score(sgdBest, X_train_fs, y_train, cv=5)\n",
    "    print(i,scores.mean())\n",
    "    results = np.append(results, scores.mean())\n",
    "\n",
    "optimal_percentil = np.where(results == results.max())[0]\n",
    "print(\"Optimal percentile of features:{0}\".format(percentiles[optimal_percentil]), \"\\n\")\n",
    "optimal_num_features = int(math.floor(percentiles[optimal_percentil]*X.shape[1]/100))\n",
    "print(\"Optimal number of features:{0}\".format(optimal_num_features), \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Automatic Document Clustering with Newsgroups5\n",
    "\n",
    "#### Your goal in this assignment is to perform clustering on the documents and compare the clusters to the actual categories. Your tasks in this problem are the following [Note: for the clustering part of this assignment you should use the kMeans module form Ch. 10 of MLA]\n",
    "\n",
    "#### A) Create your own distance function that, instead of using Euclidean distance, uses Cosine similarity. This is the distance function you will use to pass to the kMeans function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create your own distance function that, instead of using Euclidean distance, uses Cosine similarity. This is the distance function you will use to pass to the kMeans function.\n",
    "\n",
    "def cosineDist(vecA, vecB):\n",
    "    #D_norm = array([linalg.norm(data[i]) for i in range(len(data))])\n",
    "    #x_norm = linalg.norm(inX)\n",
    "    #cosines = dot(data,inX)/(D_norm * x_norm)\n",
    "    #distances = 1 - cosines\n",
    "    \n",
    "    norm_A = linalg.norm(vecA)\n",
    "    norm_B = linalg.norm(vecB)\n",
    "    cosine = dot(vecA, vecB) / norm_A * norm_B\n",
    "    distance = 1 - cosine\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load in the other fuctions we will need for the rest of this project\n",
    "from numpy import *\n",
    "\n",
    "def distEclud(vecA, vecB):\n",
    "    return sqrt(sum(power(vecA - vecB, 2))) #la.norm(vecA-vecB)\n",
    "\n",
    "def randCent(dataSet, k):\n",
    "    n = shape(dataSet)[1]\n",
    "    centroids = zeros((k,n), dtype=float)\n",
    "    for j in range(n): #create random cluster centers\n",
    "        minJ = min(dataSet[:,j])\n",
    "        rangeJ = float(max(dataSet[:,j]) - minJ)\n",
    "        centroids[:,j] = minJ + rangeJ * random.rand(k)\n",
    "    return centroids \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kMeans(dataSet, k, distMeas=distEclud, createCent=randCent):\n",
    "    m = shape(dataSet)[0]\n",
    "    clusterAssment = zeros((m,2))#create mat to assign data points \n",
    "                                      #to a centroid, also holds SE of each point\n",
    "    centroids = createCent(dataSet, k)\n",
    "    clusterChanged = True\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        for i in range(m):#for each data point assign it to the closest centroid\n",
    "            minDist = inf; minIndex = -1\n",
    "            for j in range(k):\n",
    "                distJI = distMeas(centroids[j,:],dataSet[i,:])\n",
    "                if distJI < minDist:\n",
    "                    minDist = distJI; minIndex = j\n",
    "            if clusterAssment[i,0] != minIndex: clusterChanged = True\n",
    "            clusterAssment[i,:] = minIndex,minDist**2\n",
    "        # print centroids\n",
    "        for cent in range(k):#recalculate centroids\n",
    "            ptsInClust = dataSet[nonzero(clusterAssment[:,0]==cent)[0]] #get all the point in this cluster - Note: this was incorrect in the original distribution.\n",
    "            if(len(ptsInClust)!=0):\n",
    "                centroids[cent,:] = mean(ptsInClust, axis=0) #assign centroid to mean - Note condition was added 10/28/2013\n",
    "    return centroids, clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def biKmeans(dataSet, k, distMeas=distEclud):\n",
    "    m = shape(dataSet)[0]\n",
    "    clusterAssment = mat(zeros((m,2)))\n",
    "    centroid0 = mean(dataSet, axis=0).tolist()[0]\n",
    "    centList =[centroid0] #create a list with one centroid\n",
    "    for j in range(m): #calc initial Error\n",
    "        clusterAssment[j,1] = distMeas(mat(centroid0), dataSet[j,:])**2\n",
    "    while (len(centList) < k):\n",
    "        lowestSSE = inf\n",
    "        for i in range(len(centList)):\n",
    "            ptsInCurrCluster = dataSet[nonzero(clusterAssment[:,0].A==i)[0],:] #get the data points currently in cluster i\n",
    "            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, 2, distMeas)\n",
    "            sseSplit = sum(splitClustAss[:,1])#compare the SSE to the currrent minimum\n",
    "            sseNotSplit = sum(clusterAssment[nonzero(clusterAssment[:,0].A!=i)[0],1])\n",
    "            print(\"sseSplit, and notSplit: \",sseSplit,sseNotSplit)\n",
    "            if (sseSplit + sseNotSplit) < lowestSSE:\n",
    "                bestCentToSplit = i\n",
    "                bestNewCents = centroidMat\n",
    "                bestClustAss = splitClustAss.copy()\n",
    "                lowestSSE = sseSplit + sseNotSplit\n",
    "        bestClustAss[nonzero(bestClustAss[:,0] == 1)[0],0] = len(centList) #change 1 to 3,4, or whatever\n",
    "        bestClustAss[nonzero(bestClustAss[:,0] == 0)[0],0] = bestCentToSplit\n",
    "        print('the bestCentToSplit is: ',bestCentToSplit)\n",
    "        print('the len of bestClustAss is: ', len(bestClustAss))\n",
    "        centList[bestCentToSplit] = bestNewCents[0,:].tolist()[0]#replace a centroid with two best centroids \n",
    "        centList.append(bestNewCents[1,:].tolist()[0])\n",
    "        clusterAssment[nonzero(clusterAssment[:,0].A == bestCentToSplit)[0],:]= bestClustAss#reassign new clusters, and SSE\n",
    "    return mat(centList), clusterAssment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Load the data set. Then, split the data set (the document x term matrix) and set aside 20% for later use (see below). Use the 80% segment for clustering in the next part. The 20% portion must be a random subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9328, 2500)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt(r\"/Users/sarahcummings/Documents/csc478/assignment3/newsgroups5/matrix.txt\",delimiter=\",\",dtype=int)\n",
    "#data = np.genfromtxt(r\"C:\\Users\\scummings\\Desktop\\MyFiles\\school\\csc478_3\\newsgroups5\\matrix.txt\",delimiter=\",\",dtype=int)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa' 'aargh' 'aaron' ..., 'zw' 'zx' 'zz']\n"
     ]
    }
   ],
   "source": [
    "terms=np.genfromtxt(r\"/Users/sarahcummings/Documents/csc478/assignment3/newsgroups5/terms.txt\",delimiter=\",\",dtype=str)\n",
    "#terms = np.genfromtxt(r\"C:\\Users\\scummings\\Desktop\\MyFiles\\school\\csc478_3\\newsgroups5\\terms.txt\",delimiter=\",\",dtype=str)\n",
    "\n",
    "terms.shape\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataT=data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) As in the case of Assignment 2, transform the term-frequencies to tfxidf values. Be sure to maintain DF values for each of the terms in the dictionary. ["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2500.  2500.  2500. ...,  2500.  2500.  2500.]\n",
      " [ 2500.  2500.  2500. ...,  2500.  2500.  2500.]\n",
      " [ 2500.  2500.  2500. ...,  2500.  2500.  2500.]\n",
      " ..., \n",
      " [ 2500.  2500.  2500. ...,  2500.  2500.  2500.]\n",
      " [ 2500.  2500.  2500. ...,  2500.  2500.  2500.]\n",
      " [ 2500.  2500.  2500. ...,  2500.  2500.  2500.]]\n"
     ]
    }
   ],
   "source": [
    "# concatenate the df\n",
    "#concatData = np.concatenate((d_train, d_test), axis=1)\n",
    "concatData=dataT\n",
    "\n",
    "# Find document frequencies \n",
    "DF = np.array((concatData!=0).sum(0))\n",
    "\n",
    "\n",
    "NTerms=len(concatData [0,:])\n",
    "NDocs = len(concatData [:,0])\n",
    "# Create a matrix with all entries =NDocs\n",
    "NMatrix = np.ones(np.shape(concatData ), dtype=float)*NDocs\n",
    "print(NMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert each entry into IDF values\n",
    "\n",
    "#IDF = log2(divide(NMatrix, DF))\n",
    "IDF = np.log2(np.divide(NMatrix, DF))\n",
    "\n",
    "# Compute the TF x iDF values for each document term\n",
    "TD_tfidf = concatData  * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transpose the data\n",
    "#DT_tfidf = TD_tfidf.T\n",
    "#trainNum = 0.8 * len(DT_tfidf)\n",
    "#trainDT_tfidf = DT_tfidf[:trainNum,:]\n",
    "#testDT_tfidf = DT_tfidf[trainNum:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the current categories\n",
    "labels=np.genfromtxt(r\"/Users/sarahcummings/Documents/csc478/assignment3/newsgroups5/classes.txt\",skip_header=1, usecols=(1),dtype=str)\n",
    "#labels = np.genfromtxt(r\"C:\\Users\\scummings\\Desktop\\MyFiles\\school\\csc478_3\\newsgroups5\\classes.txt\",skip_header=1, usecols=(1),dtype=str)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#trainNum\n",
    "#termsTrain=terms[1:7463]\n",
    "#termsTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Be sure to maintain the correspondence between the dictionary terms and the matrix rows\n",
    "terms_dict = dict(zip(terms, np.array((dataT!=0).sum(0))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 9328) (500, 9328) (2000,) (500,)\n"
     ]
    }
   ],
   "source": [
    "train, test, train_label, test_label = train_test_split(TD_tfidf,labels,test_size=0.20,random_state=45)\n",
    "print(train.shape,test.shape,train_label.shape,test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Perform Kmeans clustering on the training data. Write a function to display the top N terms in each cluster along with the cluster DF values for each term and the size of the cluster. Cluster DF value for a term t in a cluster C is the percentage of docs in cluster C in which term t appears. Sort the terms in decreasing order of the DF percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centroids,clusters= kMeans(train, 5, cosineDist,randCent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.00000000e+00,   7.62835057e+05],\n",
       "       [  4.00000000e+00,   1.19055217e+06],\n",
       "       [  2.00000000e+00,   6.06268818e+05],\n",
       "       ..., \n",
       "       [  4.00000000e+00,   1.78306222e+05],\n",
       "       [  2.00000000e+00,   1.81719400e+04],\n",
       "       [  4.00000000e+00,   9.47263899e+04]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 9328)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"centroids.csv\", centroids, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"clusters.csv\", clusters, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.010397e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.885017e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.160568e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.510669e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.589476e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster             x\n",
       "0      2.0  2.010397e+05\n",
       "1      1.0  2.885017e+02\n",
       "2      1.0  5.160568e+07\n",
       "3      1.0  7.510669e+03\n",
       "4      2.0  2.589476e+06"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clusters_df = pd.read_csv(r\"/Users/sarahcummings/Documents/csc478/assignment3/newsgroups5/clusters.csv\",encoding = \"ISO-8859-1\", low_memory=False, names=[\"cluster\",\"x\"])\n",
    "\n",
    "#clusters_df = pd.read_csv(r\"C:\\Users\\scummings\\Desktop\\MyFiles\\school\\csc478_3\\clusters.csv\",encoding = \"ISO-8859-1\", low_memory=False, names=[\"cluster\",\"x\"])\n",
    "clusters_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: sort is deprecated, use sort_values(inplace=True) for INPLACE sorting\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0      81\n",
       "4.0     114\n",
       "2.0     693\n",
       "3.0    2665\n",
       "1.0    3909\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts=clusters_df['cluster'].value_counts()\n",
    "counts.sort('cluster')\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counts2 = np.array([[0,81]],[[1,3909]],[[2,693]],[[3,2665]],[[4,114]])\n",
    "#x = np.array([2, 3, 1, 0])\n",
    "#counts = np.array([[ 0,counts[0]], [1,counts[1]], [ 2,627],[3,2688],[4,114]])\n",
    "counts[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster: 0\n",
      "\tTerms\t\tDF\t\tCluster\n",
      "             ax\t\t15.00\t\t46258.070\n",
      "            max\t\t19.00\t\t3178.463\n",
      "             pl\t\t20.00\t\t279.792\n",
      "            giz\t\t8.00\t\t147.798\n",
      "             qq\t\t10.00\t\t67.709\n",
      "\n",
      "Cluster: 1\n",
      "\tTerms\t\tDF\t\tCluster\n",
      "         window\t\t381.00\t\t2.997\n",
      "           file\t\t257.00\t\t2.262\n",
      "           sale\t\t326.00\t\t1.460\n",
      "         driver\t\t120.00\t\t1.400\n",
      "          drive\t\t150.00\t\t1.312\n",
      "\n",
      "Cluster: 2\n",
      "\tTerms\t\tDF\t\tCluster\n",
      "             ax\t\t15.00\t\t31484.125\n",
      "            max\t\t19.00\t\t2149.481\n",
      "             pl\t\t20.00\t\t415.625\n",
      "            bxn\t\t8.00\t\t364.659\n",
      "            giz\t\t8.00\t\t323.221\n",
      "\n",
      "Cluster: 3\n",
      "\tTerms\t\tDF\t\tCluster\n",
      "            god\t\t312.00\t\t2.593\n",
      "            kei\t\t297.00\t\t1.996\n",
      "           game\t\t338.00\t\t1.739\n",
      "      christian\t\t251.00\t\t1.640\n",
      "          peopl\t\t522.00\t\t1.475\n",
      "\n",
      "Cluster: 4\n",
      "\tTerms\t\tDF\t\tCluster\n",
      "             cx\t\t9.00\t\t294.044\n",
      "             uw\t\t12.00\t\t168.605\n",
      "             te\t\t6.00\t\t83.160\n",
      "             sq\t\t9.00\t\t78.472\n",
      "             ww\t\t6.00\t\t77.358\n"
     ]
    }
   ],
   "source": [
    "n=5\n",
    "for i in range(len(centroids)):\n",
    "        print(\"\\nCluster:\",i)\n",
    "        centroids2=centroids[i,:]\n",
    "        temp = np.ravel(centroids[i,:])\n",
    "        ind = np.argpartition(temp, -n)[-n:]\n",
    "        ind = ind[np.argsort(-temp[ind])]\n",
    "        print(\"\\tTerms\\t\\tDF\\t\\tCluster\")\n",
    "        for index in ind:\n",
    "            print(\"%15s\\t\\t%.2f\\t\\t%.3f\" %(terms[index],terms_dict[terms[index]],temp[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save it as a function\n",
    "def clustersOutput(centroids,n,terms,terms_dict,counts):\n",
    "    for i in range(len(centroids)):\n",
    "        print(\"\\nCLUSTER:\",i,\"results\")\n",
    "        print(\"Number of documents in cluster:\",counts[i])\n",
    "        centroids2=centroids[i,:]\n",
    "        temp = np.ravel(centroids[i,:])\n",
    "        ind = np.argpartition(temp, -n)[-n:]\n",
    "        ind = ind[np.argsort(-temp[ind])]\n",
    "        print(\"\\tTerms\\t\\tDF\\t\\tSize\")\n",
    "        for index in ind:\n",
    "            print(\"%15s\\t\\t%.2f\\t\\t%.3f\" %(terms[index],terms_dict[terms[index]],temp[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLUSTER: 0 results\n",
      "Number of documents in cluster: 81\n",
      "\tTerms\t\tDF\t\tSize\n",
      "             ax\t\t15.00\t\t46258.070\n",
      "            max\t\t19.00\t\t3178.463\n",
      "             pl\t\t20.00\t\t279.792\n",
      "            giz\t\t8.00\t\t147.798\n",
      "             qq\t\t10.00\t\t67.709\n",
      "\n",
      "CLUSTER: 1 results\n",
      "Number of documents in cluster: 3909\n",
      "\tTerms\t\tDF\t\tSize\n",
      "         window\t\t381.00\t\t2.997\n",
      "           file\t\t257.00\t\t2.262\n",
      "           sale\t\t326.00\t\t1.460\n",
      "         driver\t\t120.00\t\t1.400\n",
      "          drive\t\t150.00\t\t1.312\n",
      "\n",
      "CLUSTER: 2 results\n",
      "Number of documents in cluster: 693\n",
      "\tTerms\t\tDF\t\tSize\n",
      "             ax\t\t15.00\t\t31484.125\n",
      "            max\t\t19.00\t\t2149.481\n",
      "             pl\t\t20.00\t\t415.625\n",
      "            bxn\t\t8.00\t\t364.659\n",
      "            giz\t\t8.00\t\t323.221\n",
      "\n",
      "CLUSTER: 3 results\n",
      "Number of documents in cluster: 2665\n",
      "\tTerms\t\tDF\t\tSize\n",
      "            god\t\t312.00\t\t2.593\n",
      "            kei\t\t297.00\t\t1.996\n",
      "           game\t\t338.00\t\t1.739\n",
      "      christian\t\t251.00\t\t1.640\n",
      "          peopl\t\t522.00\t\t1.475\n",
      "\n",
      "CLUSTER: 4 results\n",
      "Number of documents in cluster: 114\n",
      "\tTerms\t\tDF\t\tSize\n",
      "             cx\t\t9.00\t\t294.044\n",
      "             uw\t\t12.00\t\t168.605\n",
      "             te\t\t6.00\t\t83.160\n",
      "             sq\t\t9.00\t\t78.472\n",
      "             ww\t\t6.00\t\t77.358\n"
     ]
    }
   ],
   "source": [
    "c=clustersOutput(centroids,n,terms,terms_dict,counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E) Using the cluster assignments from Kmeans clustering, compare your 5 clusters to the 5 pre-assigned classes by computing the Completeness and Homogeneity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness Score:  0.766973056913\n",
      "Homogeneity:  0.346899653235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "\n",
    "\n",
    "#labelsTrain=labels[1:7463]\n",
    "#labelsTrain.shape\n",
    "#train_label, test_label\n",
    "print(\"Completeness Score: \",completeness_score(train_label,ravel(clusters.T[0])))\n",
    "print(\"Homogeneity: \",homogeneity_score(train_label,ravel(clusters.T[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### F) Finally, using your cluster assignments as class labels, categorize each of the documents in the 20% set-aside data into each of the appropriate cluster. Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
